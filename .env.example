# Environment (development | production)
ENVIRONMENT=development

# LLM Provider (openai | ollama)
LLM_PROVIDER=ollama

# Ollama (Development - Local Docker)
OLLAMA_BASE_URL=http://localhost:11434
# Modelos recomendados (tener en cuenta memoria Docker):
# - phi3:mini (~2.2GB) - Mejor calidad, requiere 4GB+ Docker memory
OLLAMA_MODEL=phi3:mini
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# OpenAI (Production)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
USE_OPENAI_EMBEDDINGS=false

# ChromaDB
CHROMA_PERSIST_DIRECTORY=./data/chroma_db
